import os
import json
from dataclasses import dataclass
from typing import List, Dict, Any
import requests
from dotenv import load_dotenv
from pathlib import Path
from datetime import datetime, timedelta, timezone
import asyncio  # æ–°å¢ï¼šç”¨äºå¹¶å‘è°ƒç”¨ LLM
from spider.ddl_spider import collect_all_assignment_texts

# ======================= LLM é…ç½®éƒ¨åˆ† =======================

@dataclass
class LLMConfig:
    model_name: str
    api_key: str
    api_endpoint: str
    api_version: str = ""
    temperature: float = 0.3
    max_tokens: int = 4000


def get_llm_config() -> LLMConfig:
    env_path = Path(__file__).resolve().parent / ".env"  # ä¸ç®¡ä»å“ªå„¿ python app.pyï¼Œéƒ½ä¼šåŠ è½½å’Œè¿™ä¸ªæ–‡ä»¶åŒç›®å½•ä¸‹çš„ .env
    load_dotenv(env_path)
    api_key = os.getenv("QWEN_API_KEY")
    model_name = os.getenv("QWEN_MODEL_NAME")
    api_endpoint = os.getenv("QWEN_BASE_URL")

    # åˆ›å»º LLM é…ç½®
    llm_config = LLMConfig(
        model_name=model_name,
        api_key=api_key,
        api_endpoint=api_endpoint,
        api_version="",
        temperature=0.5,    # é™ä½éšæœºæ€§ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
        max_tokens=4000,    # ç¡®ä¿å“åº”è¶³å¤Ÿé•¿
    )
    return llm_config


# ======================= è°ƒç”¨ LLM çš„åº•å±‚å‡½æ•°ï¼ˆå•æ¬¡è°ƒç”¨ï¼‰ =======================

def call_llm_for_deadlines(raw_items: List[Dict[str, str]],
                           llm_config: LLMConfig) -> Dict[str, Any]:
    """
    è¾“å…¥ï¼š
        raw_items: ç”± ddl_spider.collect_all_assignment_texts(session) è¿”å›çš„åˆ—è¡¨ï¼Œ
                   æ¯æ¡å½¢å¦‚ {"è¯¾ç¨‹åç§°": ..., "åç§°": ..., "ç»†åˆ™": ...}

    è¾“å‡ºï¼š
        ä¸€ä¸ª dict:
        {
          "deadlines": [
            { "name": "...", "deadline": "YYYY-MM-DD HH:MM", "message": "...", "status": 0/1 },
            ...
          ]
        }
    """

    # 0) è®¡ç®—å½“å‰åŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²
    beijing_tz = timezone(timedelta(hours=8))
    beijing_now = datetime.now(beijing_tz)
    beijing_now_str = beijing_now.strftime("%Y-%m-%d %H:%M")

    # 1) æ‹¼åŸå§‹æ¡ç›®ï¼Œæ–¹ä¾¿ LLM ç†è§£
    lines = []
    for idx, item in enumerate(raw_items, start=1):
        course_name = item.get("è¯¾ç¨‹åç§°", "")
        name = item.get("åç§°", "")
        detail = item.get("ç»†åˆ™", "")
        lines.append(f"[{idx}] è¯¾ç¨‹ï¼š{course_name}\nåç§°ï¼š{name}\nç»†åˆ™ï¼š{detail}")
    raw_block = "\n\n".join(lines)

    # 2) prompt
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©æ•´ç†è¯¾ç¨‹ä½œä¸šä¸DDLçš„åŠ©æ‰‹ã€‚\n"
        f"å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰æ˜¯ï¼š{beijing_now_str}ã€‚\n"
        "ä½ å°†çœ‹åˆ°è‹¥å¹²åŸå§‹æ¡ç›®ï¼Œæ¯æ¡åŒ…å«ï¼šè¯¾ç¨‹åç§°ã€åç§°ï¼ˆä½œä¸šåï¼‰ã€ç»†åˆ™ï¼ˆåŒ…å«æˆªæ­¢æ—¶é—´è¯´æ˜ç­‰ï¼‰ã€‚\n"
        "ä½ çš„ä»»åŠ¡æ˜¯ï¼šæå–æ¸…æ´—åçš„ä»»åŠ¡åˆ—è¡¨ï¼Œç»Ÿä¸€è¾“å‡ºä¸º JSON å¯¹è±¡ï¼Œé”®åä¸º \"deadlines\"ï¼Œ"
        "å¯¹åº”ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n"
        "  - name: ä»»åŠ¡åç§°ï¼ˆä¼˜å…ˆç”¨æ¡ç›®ä¸­çš„â€œåç§°â€ï¼Œå¿…è¦æ—¶å¯ç¨ä½œç²¾ç®€ï¼Œå¦‚æœå•çœ‹â€œåç§°â€çœ‹ä¸å‡ºæ˜¯å“ªä¸€é—¨è¯¾ç¨‹çš„ï¼Œä½ éœ€è¦åŠ ä¸Šè¯¾ç¨‹åç§°ï¼‰ã€‚\n"
        "  - deadline: æˆªæ­¢æ—¶é—´ï¼Œç»Ÿä¸€æ ¼å¼ä¸º \"YYYY-MM-DD HH:MM\"ï¼ˆ24å°æ—¶åˆ¶ï¼‰ï¼Œ"
        "    å¦‚æœæ— æ³•ç¡®å®šå…·ä½“æ—¶é—´ï¼Œå¡« nullã€‚\n"
        "  - message: å¯¹ä»»åŠ¡çš„ç®€çŸ­è¯´æ˜ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨â€œç»†åˆ™â€æˆ–æç‚¼ä¸€ä¸¤å¥è¯ï¼Œè¯­è¨€è¦ç©æœ€è¿‘çš„æ¢—ï¼Œè¦æœ‰æ„æ€ã€‚"
        "    å¦‚æœæˆªæ­¢æ—¥æœŸä¸´è¿‘ï¼Œä½ å¯ä»¥åŠ ä¸Šå‚¬ä¿ƒå®Œæˆçš„è¯è¯­ï¼Œæ³¨æ„åŸºäºå½“å‰åŒ—äº¬æ—¶é—´è¿›è¡Œåˆ¤æ–­ã€‚\n"
        "  - status: 0 æˆ– 1ã€‚çº¦å®š 0 è¡¨ç¤ºç´§æ€¥ï¼ˆæ¯”å¦‚è·ç¦»ç°åœ¨å¾ˆè¿‘ / æˆªæ­¢æ—¶é—´å·²è¿‡æˆ–å³å°†åˆ°æœŸï¼‰ï¼Œ"
        "    1 è¡¨ç¤ºä¸ç´§æ€¥ã€‚å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¯·é»˜è®¤ 1ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "  - åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œé”®åå¿…é¡»æ˜¯ \"deadlines\"ï¼Œå¯¹åº”ä¸€ä¸ªæ•°ç»„ã€‚\n"
        "  - ä¸è¦è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šã€æ³¨é‡Šæˆ–å¤šä½™æ–‡æœ¬ã€‚\n"
        "  - åˆç†å»é‡ï¼šåŒä¸€ä¸ªä½œä¸šå¦‚æœé‡å¤å‡ºç°ï¼Œåªä¿ç•™ä¸€æ¡å³å¯ã€‚\n"
    )

    user_prompt = (
        "ä¸‹é¢æ˜¯ä»æ•™å­¦å¹³å°çˆ¬å–åˆ°çš„åŸå§‹ä½œä¸šæ¡ç›®ï¼Œè¯·ä½ æŒ‰ç…§ä¸Šè¿°è¦æ±‚è¿›è¡Œæ¸…æ´—ã€è§£æå¹¶è¾“å‡º JSONï¼š\n\n"
        f"{raw_block}\n\n"
        "è¯·åªè¿”å› JSON å¯¹è±¡ï¼Œä¾‹å¦‚ï¼š\n"
        "{\n"
        "  \"deadlines\": [\n"
        "    { \"name\": \"ä½œä¸š1\", \"deadline\": \"2025-12-01 23:59\", \"message\": \"å®Œæˆç¬¬3ç« \", \"status\": 0 },\n"
        "    { \"name\": \"Project Milestone\", \"deadline\": \"2025-12-15 12:00\", \"message\": \"æäº¤åŸå‹\", \"status\": 1 }\n"
        "  ]\n"
        "}\n"
    )

    headers = {
        "Authorization": f"Bearer {llm_config.api_key}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": llm_config.model_name,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "temperature": llm_config.temperature,
        "max_tokens": llm_config.max_tokens,
    }

    base_url = llm_config.api_endpoint.rstrip("/")
    url = f"{base_url}/chat/completions"
    print("DEBUG LLM URL:", url)

    resp = requests.post(url, headers=headers, json=payload, timeout=600)
    resp.raise_for_status()
    data = resp.json()

    try:
        content = data["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as e:
        raise ValueError(f"LLM è¿”å›ç»“æ„å¼‚å¸¸: {data}") from e

    try:
        parsed = json.loads(content)
    except json.JSONDecodeError as e:
        raise ValueError(f"LLM è¿”å›çš„å†…å®¹ä¸æ˜¯åˆæ³• JSON: {content}") from e

    if "deadlines" not in parsed or not isinstance(parsed["deadlines"], list):
        raise ValueError(f"LLM è¿”å› JSON ä¸­ç¼ºå°‘ 'deadlines' å­—æ®µ: {parsed}")

    return parsed


# ======================= å¹¶å‘è°ƒç”¨ç›¸å…³çš„è¾…åŠ©å‡½æ•° =======================

def _chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """æŠŠåˆ—è¡¨æŒ‰å›ºå®šå¤§å°åˆ‡ç‰‡ï¼Œæ¯”å¦‚ chunk_size=2 æ—¶ï¼š[0,1],[2,3],[4,5]..."""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]


async def _call_llm_for_deadlines_async(raw_items: List[Dict[str, str]],
                                        llm_config: LLMConfig) -> Dict[str, Any]:
    """
    å¼‚æ­¥åŒ…è£…ï¼šæŠŠåŸæ¥çš„åŒæ­¥ call_llm_for_deadlines ä¸¢è¿›çº¿ç¨‹æ± ï¼Œ
    è¿™æ ·ä¸ä¼šé˜»å¡äº‹ä»¶å¾ªç¯ï¼Œé€‚åˆå¹¶å‘æ‰§è¡Œã€‚
    """
    return await asyncio.to_thread(call_llm_for_deadlines, raw_items, llm_config)


async def _clean_deadlines_concurrently(raw_items: List[Dict[str, str]],
                                        llm_config: LLMConfig,
                                        chunk_size: int = 2) -> List[Dict[str, Any]]:
    """
    æ ¸å¿ƒï¼šæŠŠ raw_items æ¯ chunk_size æ¡åˆ‡ä¸€å—ï¼Œå¹¶å‘è°ƒç”¨ LLM æ¸…æ´—ï¼Œ
    æœ€åæŠŠæ‰€æœ‰å—çš„ deadlines æ‹¼æ¥æˆä¸€ä¸ªå¤§åˆ—è¡¨ï¼Œé¡ºåºæ— æ‰€è°“ã€‚
    """
    chunks = _chunk_list(raw_items, chunk_size)
    if not chunks:
        return []

    print(f"æ€»å…±æœ‰ {len(raw_items)} æ¡åŸå§‹ä½œä¸šè®°å½•ï¼Œå°†è¢«åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªå—ï¼ˆæ¯å— {chunk_size} æ¡ï¼‰ã€‚")

    # ä¸ºæ¯ä¸ªå—åˆ›å»ºä¸€ä¸ªåç¨‹ä»»åŠ¡
    tasks = [
        _call_llm_for_deadlines_async(chunk, llm_config)
        for chunk in chunks
    ]

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å—çš„ LLM è°ƒç”¨
    results = await asyncio.gather(*tasks, return_exceptions=True)

    all_deadlines: List[Dict[str, Any]] = []

    for idx, res in enumerate(results):
        if isinstance(res, Exception):
            print(f"[WARN] ç¬¬ {idx} ä¸ªå—è°ƒç”¨ LLM å¤±è´¥ï¼š{res}")
            continue

        deadlines = res.get("deadlines", [])
        if not isinstance(deadlines, list):
            print(f"[WARN] ç¬¬ {idx} ä¸ªå—è¿”å›çš„ç»“æ„ä¸­ 'deadlines' å­—æ®µä¸æ˜¯åˆ—è¡¨ï¼š{res}")
            continue

        all_deadlines.extend(deadlines)

    print(f"å¹¶å‘æ¸…æ´—å®Œæˆï¼Œæ€»å…±æ±‡æ€»å¾—åˆ° {len(all_deadlines)} æ¡ deadlinesã€‚")
    return all_deadlines


# ======================= æœ€ç»ˆæš´éœ²ç»™å¤–éƒ¨çš„ä¸»å‡½æ•° =======================

def build_deadline_payload_with_llm(session, user_id: str) -> Dict[str, Any]:
    """
    é«˜å±‚å°è£…å‡½æ•°ï¼š
      1. ä½¿ç”¨ ddl_spider.collect_all_assignment_texts(session) çˆ¬å–æ‰€æœ‰è¯¾ç¨‹ä½œä¸šåŸå§‹ä¿¡æ¯
      2. æŠŠ raw_items æ¯ä¸¤æ¡åˆ‡ä¸€å—ï¼Œå¤šä¸ªåç¨‹å¹¶å‘è°ƒç”¨ LLM æ¸…æ´—ä¸ºç»“æ„åŒ–çš„ deadlines åˆ—è¡¨
      3. æ„é€ æœ€ç»ˆè¦å‘é€ç»™ /edit/deadline çš„ JSON Body:

         {
           "UserId": "1",
           "deadlines": [
             { "name": "...", "deadline": "...", "message": "...", "status": 0 },
             ...
           ]
         }

    è¿”å›ä¸Šè¿° dictã€‚
    """
    # 1) çˆ¬è™«è·å–åŸå§‹æ¡ç›®ï¼ˆåŒæ­¥ï¼‰
    raw_items = collect_all_assignment_texts(session)
    if not raw_items:
        # æ²¡æœ‰ä»»ä½•ä½œä¸šï¼Œè¿”å›ç©ºç»“æ„
        return {
            "UserId": str(user_id),
            "deadlines": [],
        }

    # 2) åŠ è½½ LLM é…ç½®
    llm_config = get_llm_config()

    # 3) ä½¿ç”¨åç¨‹å¹¶å‘ï¼Œæ¯ä¸¤æ¡ä¸€å—è°ƒç”¨ä¸€æ¬¡ LLM
    #    æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ asyncio.run åŒ…ä¸€å±‚ï¼Œè¿™ä¸ªå‡½æ•°æœ¬èº«ä»ç„¶æ˜¯åŒæ­¥æ¥å£
    deadlines = asyncio.run(
        _clean_deadlines_concurrently(raw_items, llm_config, chunk_size=2)
    )

    # 4) æ‹¼å‡ºæœ€ç»ˆè¦ POST çš„ Body
    payload = {
        "UserId": str(user_id),
        "deadlines": deadlines,
    }
    print("===== HERE is the ğŸ˜‹ payload ! =====")
    print(payload)
    return payload